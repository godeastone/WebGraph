{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7658970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read merged_features.csv\n",
    "features_df = pd.read_csv('../../result/merged_features.csv')\n",
    "\n",
    "# Read merged_labelled.csv\n",
    "labelled_df = pd.read_csv('../../result/merged_labelled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "914abf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(features_df, labelled_df[['name', 'label']], on='name', how='left')\n",
    "data.to_csv('../../merged_features_with_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f59a5ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, make_scorer\n",
    "from sklearn.utils import resample\n",
    "from joblib import dump, load\n",
    "import pickle\n",
    "\n",
    "csv_path = \"/data4/shine/WebGraph/result/merged_features_with_label.csv\"\n",
    "\n",
    "os.getcwd()\n",
    "data = pd.read_csv(csv_path)\n",
    "#data = data.sample(frac=1) #row shuffle\n",
    "# print(type(data))\n",
    "# print(data.head())\n",
    "\n",
    "nCar = data.shape[0]\n",
    "nVar = data.shape[1]\n",
    "print('nCar: %d' % nCar, 'nVar: %d' % nVar )\n",
    "\n",
    "X = data.drop(\"CLASS\", axis=1)\n",
    "y = data[\"CLASS\"]\n",
    "\n",
    "count_class_0, count_class_1 = data['CLASS'].value_counts()\n",
    "print(\"-----\")\n",
    "print(\"NonAD (before dropping) : {}\".format(count_class_0))\n",
    "print(\"AD (before dropping) : {}\".format(count_class_1))\n",
    "\n",
    "print(\"-----\")\n",
    "print(\"NonAD (after dropping) : {}\".format(count_class_0))\n",
    "print(\"AD (after dropping) : {}\".format(count_class_1))\n",
    "print(\"Ratio : {:.1f} : {:.1f}\".format(count_class_0 / (count_class_0 + count_class_1) * 100, count_class_1 / (count_class_0 + count_class_1) * 100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d7b7a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "Class label: 0 train count: 337613 test count: 37513\n",
      "Class label: 1 train count: 51433 test count: 5715\n",
      "Fold  1\n",
      "Fold  2\n",
      "Fold  3\n",
      "Fold  4\n",
      "Fold  5\n",
      "Fold  6\n",
      "Fold  7\n",
      "Fold  8\n",
      "Fold  9\n",
      "Average score: 0.9603729064495234\n",
      "Average precision: 0.8997203355972833\n",
      "Average recall: 0.7881014873140857\n"
     ]
    }
   ],
   "source": [
    "# Define the stratified cross-validation object\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "to_exclude = [\"DOMAIN_NAME\", \"NODE_ID\", \"FEATURE_KATZ_CENTRALITY\", \"FEATURE_FIRST_PARENT_KATZ_CENTRALITY\", \"FEATURE_SECOND_PARENT_KATZ_CENTRALITY\"]\n",
    "\n",
    "accuracy_history = []\n",
    "precision_history = []\n",
    "recall_history = []\n",
    "\n",
    "# For each fold\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    \n",
    "    print(\"Fold \", fold)\n",
    "    if fold != 0:\n",
    "        continue\n",
    "    \n",
    "    fold_train_y = y[train_index]\n",
    "    fold_test_y = y[test_index]\n",
    "    \n",
    "    for class_label in np.unique(y):\n",
    "        train_count = np.count_nonzero(fold_train_y == class_label)\n",
    "        test_count = np.count_nonzero(fold_test_y == class_label)\n",
    "        if fold == 0 or fold == 5 or fold == 9:\n",
    "            print(\"Class label:\", class_label, \"train count:\", train_count, \"test count:\", test_count)\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    X_train = X_train.drop(to_exclude, axis=1)\n",
    "    X_test = X_test.drop(to_exclude, axis=1)\n",
    "\n",
    "    # Define classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    # Train\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    accuracy_history.append(accuracy_score(y_test, y_pred))\n",
    "    precision_history.append(precision_score(y_test, y_pred))\n",
    "    recall_history.append(recall_score(y_test, y_pred))\n",
    "\n",
    "# Print\n",
    "print(\"Average score:\", np.mean(accuracy_history))\n",
    "print(\"Average precision:\", np.mean(precision_history))\n",
    "print(\"Average recall:\", np.mean(recall_history))\n",
    "\n",
    "# Save\n",
    "with open('../saved_model/rf_model_origperc.pt', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64d94719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT QUERIES\n",
    "# variables\n",
    "query_size = 130000\n",
    "\n",
    "data2 = pd.read_csv(csv_path + csv_name)\n",
    "# data2 = data2.sample(frac=1) #row shuffle\n",
    "X = data2.drop(\"CLASS\", axis=1)\n",
    "y = data2[\"CLASS\"]\n",
    "\n",
    "# concate\n",
    "X = X.drop(to_exclude, axis=1)\n",
    "\n",
    "y_result = clf.predict(X)\n",
    "y_result = pd.DataFrame(y_result, columns=[\"CLASS\"])\n",
    "y_label = pd.DataFrame(y, columns=[\"CLASS\"])\n",
    "instances_concat = pd.concat([X, y_result], axis=1)\n",
    "remaining_concat = pd.concat([X, y_label], axis=1)\n",
    "\n",
    "instances_concat.to_csv(\"/home/shine/PoisoningAttack/dataset/temp_org_for_surrogate.csv\", index=False)\n",
    "remaining_concat.to_csv(\"/home/shine/PoisoningAttack/dataset/temp_org_for_inversion.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0eeefb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n",
      "Int64Index([345816,  11419, 158916,  59153,  25011,  30022, 166354, 212005,\n",
      "            222572, 406669,\n",
      "            ...\n",
      "            205380, 227173, 396351, 400624,   9949, 214255, 196664, 108121,\n",
      "            393368, 144911],\n",
      "           dtype='int64', length=130000)\n",
      "321\n"
     ]
    }
   ],
   "source": [
    "selcted_query = pd.read_csv(csv_path + \"preprocessed_temp_org_for_surrogate.csv\")\n",
    "remaining_queries = pd.read_csv(csv_path + \"preprocessed_temp_org_for_inversion.csv\")\n",
    "\n",
    "# count \"all\" instances\n",
    "if query_size == \"all\":\n",
    "    query_size = len(instances_concat)\n",
    "    print(\"all query size : {}\".format(query_size))\n",
    "\n",
    "# Select random N queries\n",
    "selcted_query = selcted_query.sample(n=query_size)\n",
    "\n",
    "# save\n",
    "if query_size == len(instances_concat):\n",
    "    query_size = \"all\"\n",
    "print(selcted_query.shape[1])\n",
    "selcted_query.to_csv(\"/home/shine/PoisoningAttack/dataset/for_surrogate/query_origperc_{}.csv\".format(query_size), index=False)\n",
    "\n",
    "# save remaining query\n",
    "selected_indices = selcted_query.index\n",
    "print(selected_indices)\n",
    "remaining_queries = remaining_queries.drop(selected_indices)\n",
    "remaining_queries = remaining_queries[remaining_queries[\"CLASS\"] == 1]\n",
    "print(remaining_queries.shape[1])\n",
    "remaining_queries.to_csv(\"/home/shine/PoisoningAttack/dataset/origperc_{}_for_inversion.csv\".format(query_size), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0dbea5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3316536221007112\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = \"/home/shine/PoisoningAttack/dataset/\"\n",
    "\n",
    "# csv_name_ad = \"origperc_130000_for_inversion.csv\"\n",
    "# csv_name_pgd = \"perturbed_features_pgd.csv\"\n",
    "csv_name_nbackdoor = \"reordered_bin_processed_perturbed_features_nbackdoor_bin_original_perc0.3_eps4.0.csv\"\n",
    "\n",
    "# data_ad = pd.read_csv(csv_path + csv_name_ad)\n",
    "# data_pgd = pd.read_csv(csv_path + csv_name_pgd)\n",
    "data_nbackdoor = pd.read_csv(csv_path + csv_name_nbackdoor)\n",
    "\n",
    "# X_ad = data_ad.drop('CLASS', axis=1)\n",
    "# feature_columns_pgd = list(data_pgd.columns.difference(['CLASS']))\n",
    "X_nbackdoor = data_nbackdoor.drop('CLASS', axis=1)\n",
    "\n",
    "# y_ad = data_ad[['CLASS']]\n",
    "# y_pgd = after_mapping_target_pgd\n",
    "y_nbackdoor = data_nbackdoor[['CLASS']]\n",
    " \n",
    "# predict_ad = clf.predict(X_ad)\n",
    "# predict_pgd = clf.predict(X_pgd)\n",
    "predict_nbackdoor = clf.predict(X_nbackdoor)\n",
    "\n",
    "# print(y_ad, predict_ad)\n",
    "# print(accuracy_score(y_pgd, predict_pgd))\n",
    "print(accuracy_score(y_nbackdoor, predict_nbackdoor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f824a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_csv_path = \"/home/shine/PoisoningAttack/dataset/features_rf_only_cat2.csv\"\n",
    "df = pd.read_csv(perturbed_csv_path)\n",
    "to_exclude = [\"DOMAIN_NAME\", \"NODE_ID\", \"FEATURE_KATZ_CENTRALITY\", \"FEATURE_FIRST_PARENT_KATZ_CENTRALITY\", \"FEATURE_SECOND_PARENT_KATZ_CENTRALITY\"]\n",
    "\n",
    "df = df.drop(to_exclude, axis=1)\n",
    "y_pred = clf.predict(df)\n",
    "\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
